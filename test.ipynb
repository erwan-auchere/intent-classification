{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, model, importlib\n",
    "importlib.reload(model)\n",
    "\n",
    "context = [\n",
    "    \"Is there anyone who doesn't know Nancy?\",\n",
    "    \"Do you - Do you know Nancy?\",\n",
    "    \"Me?\",\n",
    "    \"Mm-hmm\",\n",
    "    \"I know Nancy\"\n",
    "]\n",
    "speaker_change = [1, 0, 1, 0, 0] # 1 indicates a change in the speaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', \"doesn't\", 'I', 'Nancy', 'Do', 'anyone', 'there', 'Is', 'know', 'you', 'who', 'Nancy?', 'Me?', 'Mm-hmm', '-']\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing fait à la va-vite pour vérifier que l'encodeur ne renvoie pas d'erreur\n",
    "vocab = [\"\"] + list(set(\" \".join(context).split()))\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7,  6,  5, 10,  1,  8, 11],\n",
       "        [ 4,  9, 14,  4,  9,  8, 11],\n",
       "        [12,  0,  0,  0,  0,  0,  0],\n",
       "        [13,  0,  0,  0,  0,  0,  0],\n",
       "        [ 2,  8,  3,  0,  0,  0,  0]])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len = max([len(sentence.split()) for sentence in context])\n",
    "\n",
    "X = torch.tensor([\n",
    "    [vocab.index(word) for word in sentence.split()] + [0 for _ in range(max_len-len(sentence.split()))]\n",
    "    for sentence in context\n",
    "])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 7, 15])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ohe = torch.nn.functional.one_hot(X).unsqueeze(0).type(torch.float32)\n",
    "X_ohe.shape\n",
    "# (batch_size, sequence_length, max_sentence_length, input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P = torch.tensor(speaker_change).unsqueeze(0)\n",
    "P.shape\n",
    "# (batch_size, sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 256])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = model.HierarchicalEncoder(input_size = len(vocab))\n",
    "encoder(X_ohe, P).shape\n",
    "# (bacth_size, 2*hidden_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "HierarchicalEncoder                      --\n",
       "├─GRU: 1-1                               111,360\n",
       "├─DiscontinuedGRU: 1-2                   --\n",
       "│    └─GRUCell: 2-1                      148,224\n",
       "│    └─GRUCell: 2-2                      148,224\n",
       "├─GRU: 1-3                               296,448\n",
       "=================================================================\n",
       "Total params: 704,256\n",
       "Trainable params: 704,256\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchinfo\n",
    "\n",
    "torchinfo.summary(encoder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5895846bd8895370c40c21e36c79c4eb41c3a72753ef20f6391cf79dc6750c48"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
