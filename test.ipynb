{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, model, importlib\n",
    "importlib.reload(model);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset daily_dialog (C:/Users/Erwan/.cache/huggingface/datasets/daily_dialog/default/1.0.0/1d0a58c7f2a4dab5ed9d01dbde8e55e0058e589ab81fce5c2df929ea810eabcd)\n",
      "100%|██████████| 3/3 [00:00<00:00, 61.65it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['dialog', 'act', 'emotion'],\n",
       "        num_rows: 11118\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['dialog', 'act', 'emotion'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['dialog', 'act', 'emotion'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datasets\n",
    "\n",
    "dataset = datasets.load_dataset('daily_dialog')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.vocab import GloVe, vocab\n",
    "\n",
    "pretrained_vectors = GloVe(name=\"6B\", dim=50)\n",
    "pretrained_vocab = vocab(pretrained_vectors.stoi)\n",
    "pretrained_vocab.insert_token(\"<unk>\", 0)\n",
    "pretrained_vocab.insert_token(\"<pad>\", 1)\n",
    "pretrained_vocab.set_default_index(0)\n",
    "pretrained_embeddings = pretrained_vectors.vectors\n",
    "pretrained_embeddings = torch.cat((torch.zeros(1,pretrained_embeddings.shape[1]),pretrained_embeddings))\n",
    "vocab_stoi = pretrained_vocab.get_stoi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "290"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from torchtext.data import get_tokenizer\n",
    "tokenizer = get_tokenizer(\"basic_english\")\n",
    "\n",
    "max_len = max([\n",
    "    len(tokenizer(sentence))\n",
    "     for dialog in dataset['train']['dialog'] + dataset['validation']['dialog'] + dataset['test']['dialog']\n",
    "     for sentence in dialog \n",
    "])\n",
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "@np.vectorize\n",
    "def numericalize(word, vocab_stoi):\n",
    "    return vocab_stoi[word] if word in vocab_stoi else 0\n",
    "\n",
    "def preprocess(sentence, max_len):\n",
    "    # Tokenizer, word to indices, padding\n",
    "    sentence = tokenizer(sentence.lower())\n",
    "    sentence = sentence + [\"<pad>\" for _ in range(max_len-len(sentence))]\n",
    "    sentence = numericalize(sentence, vocab_stoi)\n",
    "    return sentence\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each dialog, we take the first 5 utterances\n",
    "new_dataset = dict()\n",
    "for split in ['train', 'validation', 'test']:\n",
    "    new_dataset[split] = [\n",
    "        (\n",
    "            np.array([preprocess(sentence, max_len=max_len) for sentence in dialog[:5]]),\n",
    "            np.array([a for a in act[:5]])\n",
    "        )\n",
    "        for dialog, act in zip(dataset[split]['dialog'], dataset[split]['act'])\n",
    "        if len(dialog) >= 5\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 290)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dataset['train'][0][0].shape # (sequence_length, max_sentence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5,)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dataset['train'][0][1].shape # (sequence_length,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DialogActDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return dict(\n",
    "            dialog = torch.tensor(self.data[idx][0]),\n",
    "            act = torch.tensor(self.data[idx][1])\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = dict(\n",
    "    batch_size = 64,\n",
    "    shuffle = True,\n",
    "    drop_last = True\n",
    ")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    DialogActDataset(new_dataset['train']), **kwargs\n",
    ")\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    DialogActDataset(new_dataset['validation']), **kwargs\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    DialogActDataset(new_dataset['test']), **kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "Seq2SeqModel                             --\n",
       "├─Embedding: 1-1                         (20,000,050)\n",
       "├─HierarchicalEncoder: 1-2               --\n",
       "│    └─GRU: 2-1                          138,240\n",
       "│    └─DiscontinuedGRU: 2-2              --\n",
       "│    │    └─GRUCell: 3-1                 148,224\n",
       "│    │    └─GRUCell: 3-2                 148,224\n",
       "│    └─GRU: 2-3                          296,448\n",
       "├─SoftGuidedAttentionDecoder: 1-3        --\n",
       "│    └─Linear: 2-4                       513\n",
       "│    └─GRUCell: 2-5                      394,752\n",
       "├─Linear: 1-4                            1,285\n",
       "=================================================================\n",
       "Total params: 21,127,736\n",
       "Trainable params: 1,127,686\n",
       "Non-trainable params: 20,000,050\n",
       "================================================================="
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchinfo\n",
    "\n",
    "network = model.Seq2SeqModel(\n",
    "    nb_classes = 5,\n",
    "    sequence_length = 5,\n",
    "    hidden_size = 128,\n",
    "    pretrained_embeddings = pretrained_embeddings,\n",
    ")\n",
    "torchinfo.summary(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 5, 290])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_loader))['dialog'].shape\n",
    "# (batch_size, context_length, max_sentence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 5, 5])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network(next(iter(train_loader))['dialog']).shape\n",
    "# (batch_size, context_length, nb_classes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5895846bd8895370c40c21e36c79c4eb41c3a72753ef20f6391cf79dc6750c48"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
