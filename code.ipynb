{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yg_UUy9dWzsw",
        "outputId": "f0c6adda-68ca-480f-8109-0d7339d0060b",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch==1.13.1 in /usr/local/lib/python3.9/dist-packages (1.13.1+cu116)\n",
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.9/dist-packages (0.14.1)\n",
            "Requirement already satisfied: torchinfo in /usr/local/lib/python3.9/dist-packages (1.7.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.9/dist-packages (2.10.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (3.5.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch==1.13.1) (4.5.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torchtext) (2.25.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from torchtext) (4.65.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torchtext) (1.22.4)\n",
            "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (0.3.6)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.9/dist-packages (from datasets) (0.18.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.9/dist-packages (from datasets) (3.2.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from datasets) (23.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (0.13.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from datasets) (1.4.4)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (2023.3.0)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.9/dist-packages (from datasets) (0.70.14)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.9/dist-packages (from datasets) (3.8.4)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (8.4.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (1.4.4)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (4.39.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (3.0.9)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (3.1.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (1.8.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (22.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.9.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.7->matplotlib) (1.15.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->torchtext) (1.26.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->torchtext) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests->torchtext) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->torchtext) (2022.12.7)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets) (2022.7.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch==1.13.1 torchtext torchinfo datasets matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nW-UydEfWzsy",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import torch, model, importlib\n",
        "importlib.reload(model);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0SdlprX8Wzsz",
        "outputId": "14659297-11bf-4621-c3f7-480a8bbf3e51",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available():\n",
        "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89kI46CZWzs0"
      },
      "source": [
        "# Data loading and preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329,
          "referenced_widgets": [
            "2deb8e0220e744388e75fe8dfd8df8ab",
            "f7fde0d06d274e0182f00289551b4b8d",
            "89c00d36a76a42e5b9c8586fc3aa2ee8",
            "6332e8e142d14cc3bcd14ffe52aeddf0",
            "ce596d28bf9a46e085ede73f1304fdc1",
            "de34191731ed42ed8119d7004012c3c7",
            "002c2ef29658418e800681ed3cd7feab",
            "fee22764a8534a318f51b4b41249fa20",
            "0f820050f76e45dca2c0567d54572295",
            "2cd4fb9137d840cca079b37bd5c7b4ef",
            "a70685d222e34f39856124e1bebbf7ee"
          ]
        },
        "id": "x6mulqoAWzs2",
        "outputId": "3745ac78-ee00-41a4-9312-f762abe0981c",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Found cached dataset silicone (/root/.cache/huggingface/datasets/silicone/swda/1.0.0/af617406c94e3f78da85f7ea74ebfbd3f297a9665cb54adbae305b03bc4442a5)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2deb8e0220e744388e75fe8dfd8df8ab"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['Utterance', 'Dialogue_Act', 'From_Caller', 'To_Caller', 'Topic', 'Dialogue_ID', 'Conv_ID', 'Label', 'Idx'],\n",
              "        num_rows: 190709\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['Utterance', 'Dialogue_Act', 'From_Caller', 'To_Caller', 'Topic', 'Dialogue_ID', 'Conv_ID', 'Label', 'Idx'],\n",
              "        num_rows: 21203\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['Utterance', 'Dialogue_Act', 'From_Caller', 'To_Caller', 'Topic', 'Dialogue_ID', 'Conv_ID', 'Label', 'Idx'],\n",
              "        num_rows: 2714\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import datasets\n",
        "\n",
        "dataset = datasets.load_dataset('silicone', 'swda')\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "0YIcpE30Wzs3",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from torchtext.vocab import GloVe, vocab\n",
        "\n",
        "pretrained_vectors = GloVe(name=\"6B\", dim=50)\n",
        "pretrained_vocab = vocab(pretrained_vectors.stoi)\n",
        "pretrained_vocab.insert_token(\"<unk>\", 0)\n",
        "pretrained_vocab.insert_token(\"<pad>\", 1)\n",
        "pretrained_vocab.set_default_index(0)\n",
        "pretrained_embeddings = pretrained_vectors.vectors.to(device)\n",
        "pretrained_embeddings = torch.cat((torch.zeros(1,pretrained_embeddings.shape[1]),pretrained_embeddings))\n",
        "vocab_stoi = pretrained_vocab.get_stoi()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddGOEU3_Wzs3",
        "outputId": "ae057d6c-dcaa-4c0f-f647-be163941eca3",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "102"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "import numpy as np\n",
        "from torchtext.data import get_tokenizer\n",
        "tokenizer = get_tokenizer(\"basic_english\")\n",
        "\n",
        "dataset_name = 'swda'\n",
        "\n",
        "if dataset == 'daily_dialog':\n",
        "    max_len = max([\n",
        "        len(tokenizer(sentence))\n",
        "        for dialog in dataset['train']['dialog'] + dataset['validation']['dialog'] + dataset['test']['dialog']\n",
        "        for sentence in dialog \n",
        "    ])\n",
        "elif dataset_name == 'swda':\n",
        "    max_len = max([\n",
        "        len(tokenizer(sentence))\n",
        "        for sentence in dataset['train']['Utterance'] + dataset['validation']['Utterance'] + dataset['test']['Utterance']\n",
        "    ])\n",
        "else:\n",
        "    raise ValueError()\n",
        "\n",
        "max_len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "r0g4Rvj1Wzs4",
        "tags": []
      },
      "outputs": [],
      "source": [
        "@np.vectorize\n",
        "def numericalize(word, vocab_stoi):\n",
        "    return vocab_stoi[word] if word in vocab_stoi else 0\n",
        "\n",
        "def preprocess(sentence, max_len):\n",
        "    # Tokenizer, word to indices, padding\n",
        "    sentence = tokenizer(sentence.lower())\n",
        "    sentence = sentence + [\"<pad>\" for _ in range(max_len-len(sentence))]\n",
        "    sentence = numericalize(sentence, vocab_stoi)\n",
        "    return sentence\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "nBmy-csKWzs4",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# For each dialog, we take the first 5 utterances\n",
        "new_dataset = dict()\n",
        "\n",
        "if dataset_name == 'daily_dialog':\n",
        "    for split in ['train', 'validation', 'test']:\n",
        "        new_dataset[split] = [\n",
        "            (\n",
        "                np.array([preprocess(sentence, max_len=max_len) for sentence in dialog[:5]]),\n",
        "                np.array([a for a in act[:5]])\n",
        "            )\n",
        "            for dialog, act in zip(dataset[split]['dialog'], dataset[split]['act'])\n",
        "            if len(dialog) >= 5\n",
        "        ]\n",
        "elif dataset_name == 'swda':\n",
        "    for split in ['train', 'validation', 'test']:\n",
        "        out = list()\n",
        "        # We split each dialogue in dialogues of length 5\n",
        "        nb_dialogues = np.max(np.array(dataset[split]['Dialogue_ID']).astype(int)) + 1\n",
        "        current_subdialog = list()\n",
        "        current_subdialog_id = 0\n",
        "        in_current_subdialog = 0\n",
        "        for n in range(nb_dialogues):\n",
        "            if in_current_subdialog == 5:\n",
        "                current_subdialog_id += 1\n",
        "                in_current_subdialog = 0\n",
        "                out += current_subdialog\n",
        "                current_subdialog = list()\n",
        "            \n",
        "            line = dataset[split][n]\n",
        "            current_subdialog.append(\n",
        "                dict(\n",
        "                    Utterance = preprocess(line['Utterance'], max_len=max_len),\n",
        "                    Dialogue_ID = current_subdialog_id,\n",
        "                    Idx = in_current_subdialog,\n",
        "                    Label = line['Label']\n",
        "                )\n",
        "            )\n",
        "            in_current_subdialog += 1\n",
        "        \n",
        "        new_dataset[split] = out\n",
        "else:\n",
        "    raise ValueError()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_dataset['train'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1-OTA6aoR2R",
        "outputId": "7771e4aa-536d-40ba-f9d7-cd377519a6bc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Utterance': array([  101,    42,    58, 37139,    52,  1624,    60,  1341,  8567,\n",
              "            3,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "            1,     1,     1]), 'Dialogue_ID': 0, 'Idx': 0, 'Label': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "r-FgHwZiWzs5",
        "tags": []
      },
      "outputs": [],
      "source": [
        "class DialogActDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return dict(\n",
        "            dialog = torch.tensor(self.data[idx][0]),\n",
        "            act = torch.tensor(self.data[idx][1])\n",
        "        )\n",
        "\n",
        "class SwDADataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data) // 5\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        subdialog = [elt for elt in self.data if elt['Dialogue_ID']==idx]\n",
        "        subdialog = sorted(subdialog, key=lambda ut: ut['Idx'])\n",
        "        return dict(\n",
        "            dialog = torch.tensor(\n",
        "                torch.stack(\n",
        "                    [\n",
        "                        torch.tensor(ut['Utterance']) for ut in subdialog\n",
        "                    ],\n",
        "                    dim = 0\n",
        "                )\n",
        "            ),\n",
        "            act = torch.tensor([ut['Label'] for ut in subdialog])\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "oYKf6Nz7Wzs5",
        "tags": []
      },
      "outputs": [],
      "source": [
        "kwargs = dict(\n",
        "    batch_size = 32,\n",
        "    shuffle = True,\n",
        "    drop_last = True,\n",
        "    generator = torch.Generator(device=device)\n",
        ")\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    SwDADataset(new_dataset['train']), **kwargs\n",
        ")\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "    SwDADataset(new_dataset['validation']), **kwargs\n",
        ")\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    SwDADataset(new_dataset['test']), **kwargs\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "tags": [],
        "id": "lqKHNFNWQZtH"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, test_loader, device):\n",
        "    \"\"\"Measures the accuracy of `model` on `test_loader`.\"\"\"\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        correct = 0\n",
        "        for batch_idx, batch in enumerate(test_loader):\n",
        "            x = batch['dialog'].to(device)\n",
        "            target = batch['act'].to(device)\n",
        "            out = model(x)\n",
        "            out_argmax = torch.argmax(out, dim=-1)\n",
        "            correct += torch.sum( torch.where( out_argmax == target, 1, 0 ) ).item()\n",
        "            \n",
        "    return correct / len(test_loader) / kwargs['batch_size'] / 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBkeoavOQZtH"
      },
      "source": [
        "# Vanilla Attention\n",
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iaZSgtj2QZtI",
        "outputId": "d9ded347-550b-4beb-a31e-610111803e07"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "=================================================================\n",
              "Layer (type:depth-idx)                   Param #\n",
              "=================================================================\n",
              "Seq2SeqModel                             --\n",
              "├─Embedding: 1-1                         (20,000,050)\n",
              "├─HierarchicalEncoder: 1-2               --\n",
              "│    └─GRU: 2-1                          138,240\n",
              "│    └─GRU: 2-2                          296,448\n",
              "├─VanillaAttentionDecoder: 1-3           --\n",
              "│    └─Linear: 2-3                       513\n",
              "│    └─GRUCell: 2-4                      394,752\n",
              "├─Linear: 1-4                            11,051\n",
              "=================================================================\n",
              "Total params: 20,841,054\n",
              "Trainable params: 841,004\n",
              "Non-trainable params: 20,000,050\n",
              "================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "import torchinfo\n",
        "\n",
        "network = model.Seq2SeqModel(\n",
        "    pretrained_embeddings = pretrained_embeddings,\n",
        "    encoder = model.HierarchicalEncoder(\n",
        "        input_size = pretrained_embeddings.shape[1],\n",
        "        sequence_length = 5,\n",
        "        hidden_size = 128,\n",
        "        persona_level = False,\n",
        "    ),\n",
        "    decoder = model.VanillaAttentionDecoder(\n",
        "        hidden_size = 128,\n",
        "        sequence_length = 5,\n",
        "    ),\n",
        "    nb_classes = 43,\n",
        "    hidden_size = 128,\n",
        ")\n",
        "torchinfo.summary(network)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To ensure the model is actually learning something, we compute the accuracy before any training:\n",
        "evaluate(network, test_loader, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1oZq3EedU9L",
        "outputId": "e6cf247f-5926-4ca8-b00c-2174376a4de5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-f394d5e5ba3d>:25: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  dialog = torch.tensor(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.00125"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nkr6a7_uWzs7",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def train(model, train_loader, val_loader, optimizer, loss_fn, device, n_epochs=10):\n",
        "    train_losses, val_losses, val_accuracies = [], [], []\n",
        "    scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.5)\n",
        "    \n",
        "    model.to(device)\n",
        "    for epoch in range(n_epochs):\n",
        "        # Training\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "\n",
        "        for batch_idx, batch in enumerate(train_loader):\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            x = batch['dialog'].to(device)\n",
        "            target = batch['act'].to(device)\n",
        "\n",
        "            out = model(x).transpose(1,2)\n",
        "            loss = loss_fn(out, target.long())\n",
        "\n",
        "            train_loss += loss.item()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "            \n",
        "        if (epoch+1)%20 == 0: print(f'Epoch {epoch+1}/{n_epochs}, training loss: {train_loss/len(train_loader)/kwargs[\"batch_size\"]:.4g}')\n",
        "        train_losses.append(train_loss/len(train_loader)/kwargs['batch_size'])\n",
        "\n",
        "                \n",
        "        # Testing\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            loss = 0\n",
        "            for batch_idx, batch in enumerate(val_loader):\n",
        "                x = batch['dialog'].to(device)\n",
        "                target = batch['act'].to(device)\n",
        "                out = model(x).transpose(1,2)\n",
        "                loss += loss_fn(out, target.long()).item()\n",
        "                \n",
        "        if (epoch+1)%20 == 0: print(f'Epoch {epoch+1}/{n_epochs}, val loss: {loss/len(val_loader)/kwargs[\"batch_size\"]:.4g}')\n",
        "        val_losses.append(loss/len(val_loader)/kwargs['batch_size'])\n",
        "\n",
        "        acc = evaluate(network, val_loader, device)\n",
        "        if (epoch+1)%20 == 0: print(f'Epoch {epoch+1}/{n_epochs}, val accuracy: {acc:.4g}')\n",
        "        val_accuracies.append(acc)\n",
        "    \n",
        "    return train_losses, val_losses, val_accuracies\n",
        "\n",
        "train_losses, val_losses, val_accuracies = train(\n",
        "    network,\n",
        "    train_loader,\n",
        "    test_loader,\n",
        "    optimizer = torch.optim.SGD(network.parameters(), lr=0.01),\n",
        "    loss_fn = torch.nn.CrossEntropyLoss(),\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu',\n",
        "    n_epochs = 300\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TRVLPc3PWzs8",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_progress(train_losses, val_losses, val_accuracies):\n",
        "    fig, (left, right) = plt.subplots(1, 2, figsize=(16,8))\n",
        "\n",
        "    left.plot(train_losses, color='red', label='Train loss')\n",
        "    left.plot(val_losses, color='blue', label='Val loss')\n",
        "    left.legend()\n",
        "    left.set_xlabel('Epochs')\n",
        "    left.set_ylabel('Cross-entropy')\n",
        "\n",
        "    right.plot(val_accuracies, color='green', label='Val accuracy')\n",
        "    right.legend()\n",
        "    right.set_xlabel('Epochs')\n",
        "    right.set_ylabel('Accuracy')\n",
        "    fig.show()\n",
        "\n",
        "plot_progress(train_losses, val_losses, val_accuracies)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FPZ9b6hjWzs8",
        "tags": []
      },
      "outputs": [],
      "source": [
        "torch.save(network, 'model_vanilla_attention.pkl')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scSJTauXWzs8"
      },
      "source": [
        "## Evaluation with accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TdEj0fb-Wzs8",
        "tags": []
      },
      "outputs": [],
      "source": [
        "network = torch.load('model_vanilla_attention.pkl') \n",
        "evaluate(network, test_loader, device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2b8CTzsWzs8",
        "tags": []
      },
      "source": [
        "# Hard-guided Attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NcdvrzEBWzs9",
        "tags": []
      },
      "outputs": [],
      "source": [
        "network = model.Seq2SeqModel(\n",
        "    pretrained_embeddings = pretrained_embeddings,\n",
        "    encoder = model.HierarchicalEncoder(\n",
        "        input_size = pretrained_embeddings.shape[1],\n",
        "        sequence_length = 5,\n",
        "        hidden_size = 128,\n",
        "        persona_level = False,\n",
        "    ),\n",
        "    decoder = model.HardGuidedAttentionDecoder(\n",
        "        hidden_size = 128,\n",
        "        sequence_length = 5,\n",
        "    ),\n",
        "    nb_classes = 5,\n",
        "    hidden_size = 128,\n",
        ")\n",
        "torchinfo.summary(network)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KAaYf4eKWzs9",
        "tags": []
      },
      "outputs": [],
      "source": [
        "train_losses, test_losses, val_accuracies = train(\n",
        "    network,\n",
        "    train_loader,\n",
        "    test_loader,  \n",
        "    optimizer = torch.optim.SGD(network.parameters(), lr=3e-3),\n",
        "    loss_fn = torch.nn.CrossEntropyLoss(),\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu',\n",
        "    n_epochs = 300\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G8uXjNiGWzs9",
        "tags": []
      },
      "outputs": [],
      "source": [
        "plot_progress(train_losses, val_losses, val_accuracies)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z8htzNEwWzs9",
        "tags": []
      },
      "outputs": [],
      "source": [
        "torch.save(network, 'model_hard_guided.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AOmLg-gdWzs-",
        "tags": []
      },
      "outputs": [],
      "source": [
        "network = torch.load('model_hard_guided.pkl') \n",
        "evaluate(network, test_loader, device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R69oNnLBQZtK"
      },
      "source": [
        "# Soft Guided Attention\n",
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "IgN28NVlQZtK"
      },
      "outputs": [],
      "source": [
        "network = model.Seq2SeqModel(\n",
        "    pretrained_embeddings = pretrained_embeddings,\n",
        "    encoder = model.HierarchicalEncoder(\n",
        "        input_size = pretrained_embeddings.shape[1],\n",
        "        sequence_length = 5,\n",
        "        hidden_size = 128,\n",
        "        persona_level = False,\n",
        "    ),\n",
        "    decoder = model.SoftGuidedAttentionDecoder(\n",
        "        hidden_size = 128,\n",
        "        sequence_length = 5,\n",
        "    ),\n",
        "    nb_classes = 5,\n",
        "    hidden_size = 128,\n",
        ")\n",
        "torchinfo.summary(network)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "z7TZpmaIQZtL"
      },
      "outputs": [],
      "source": [
        "train_losses, test_losses, val_accuracies = train(\n",
        "    network,\n",
        "    train_loader,\n",
        "    test_loader,  \n",
        "    optimizer = torch.optim.SGD(network.parameters(), lr=3e-3),\n",
        "    loss_fn = torch.nn.CrossEntropyLoss(),\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu',\n",
        "    n_epochs = 300\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "lVe1oi3jQZtL"
      },
      "outputs": [],
      "source": [
        "plot_progress(train_losses, val_losses, val_accuracies)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "rO1RKjLQQZtL"
      },
      "outputs": [],
      "source": [
        "torch.save(network, 'model_soft_guided.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "qb6zsm8QQZtL"
      },
      "outputs": [],
      "source": [
        "network = torch.load('model_soft_guided.pkl')\n",
        "evaluate(network, test_loader, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lMU0yny1QZtL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8eRt1TwCQZtL"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "5895846bd8895370c40c21e36c79c4eb41c3a72753ef20f6391cf79dc6750c48"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2deb8e0220e744388e75fe8dfd8df8ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f7fde0d06d274e0182f00289551b4b8d",
              "IPY_MODEL_89c00d36a76a42e5b9c8586fc3aa2ee8",
              "IPY_MODEL_6332e8e142d14cc3bcd14ffe52aeddf0"
            ],
            "layout": "IPY_MODEL_ce596d28bf9a46e085ede73f1304fdc1"
          }
        },
        "f7fde0d06d274e0182f00289551b4b8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de34191731ed42ed8119d7004012c3c7",
            "placeholder": "​",
            "style": "IPY_MODEL_002c2ef29658418e800681ed3cd7feab",
            "value": "100%"
          }
        },
        "89c00d36a76a42e5b9c8586fc3aa2ee8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fee22764a8534a318f51b4b41249fa20",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0f820050f76e45dca2c0567d54572295",
            "value": 3
          }
        },
        "6332e8e142d14cc3bcd14ffe52aeddf0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2cd4fb9137d840cca079b37bd5c7b4ef",
            "placeholder": "​",
            "style": "IPY_MODEL_a70685d222e34f39856124e1bebbf7ee",
            "value": " 3/3 [00:00&lt;00:00, 29.07it/s]"
          }
        },
        "ce596d28bf9a46e085ede73f1304fdc1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de34191731ed42ed8119d7004012c3c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "002c2ef29658418e800681ed3cd7feab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fee22764a8534a318f51b4b41249fa20": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f820050f76e45dca2c0567d54572295": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2cd4fb9137d840cca079b37bd5c7b4ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a70685d222e34f39856124e1bebbf7ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}